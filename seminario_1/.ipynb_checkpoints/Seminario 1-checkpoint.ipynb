{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtrado de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "\n",
    "X, y = load_wine(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 13)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verificamos nuestros datos\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Univariate Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6 12 11  0  9 10  5  1  3  8  7  2  4]\n",
      "[ 6 12 11  0  9 10]\n"
     ]
    }
   ],
   "source": [
    "# Elegimos 4 atributos representativos\n",
    "univ_sel = SelectKBest(score_func=f_classif, k=6)\n",
    "fit = univ_sel.fit(X, y)\n",
    "\n",
    "# Imprimimos los atributos ordenados por importancia\n",
    "print(np.argsort(fit.scores_)[::-1])\n",
    "\n",
    "# Imprimimos los 6 atributos seleccionados\n",
    "print(np.argsort(fit.scores_)[::-1][:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  2  5  6  9 11]\n"
     ]
    }
   ],
   "source": [
    "# elegimos 4 atributos representativos y un modelo de regresion lineal\n",
    "model = LogisticRegression(solver='lbfgs', max_iter=10000)\n",
    "rfe = RFE(model, n_features_to_select=6)\n",
    "fit = rfe.fit(X, y)\n",
    "\n",
    "print(np.where(fit.support_)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6  9  0 11 12 10  5  4  2  8  7  3  1]\n",
      "[ 6  9  0 11 12 10]\n"
     ]
    }
   ],
   "source": [
    "model = ExtraTreesClassifier(n_estimators=10)\n",
    "model.fit(X, y)\n",
    "\n",
    "\n",
    "# Imprimimos los atributos ordenados por importancia\n",
    "print(np.argsort(model.feature_importances_)[::-1])\n",
    "\n",
    "# Imprimimos los 6 atributos seleccionados\n",
    "print(np.argsort(model.feature_importances_)[::-1][:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajuste de parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "X, y = load_boston(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.05, 'max_depth': 4, 'max_features': 0.3, 'min_samples_leaf': 3}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"learning_rate\": [0.1, 0.05, 0.02, 0.01],\n",
    "    \"max_depth\": [4, 6],\n",
    "    \"min_samples_leaf\": [3, 5, 9, 17],\n",
    "    \"max_features\": [1.0, 0.3, 0.1]\n",
    "}\n",
    "\n",
    "est = GradientBoostingRegressor(n_estimators=3000)\n",
    "gs_cv = GridSearchCV(est, param_grid).fit(X, y)\n",
    "\n",
    "# Imprimimos el mejor set de hiperparametros\n",
    "print(gs_cv.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
